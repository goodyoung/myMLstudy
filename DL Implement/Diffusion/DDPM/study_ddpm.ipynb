{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00108550-0fae-4996-a17a-99aa2f6d649d",
   "metadata": {},
   "source": [
    "## DDPM 기초 구현\n",
    "\n",
    "### 구현해야될 항목\n",
    "  - 각종 변수들 ($\\alpha, \\tilde\\alpha, \\mu, ...$)\n",
    "  - 훈련 코드\n",
    "  - 샘플링 코드\n",
    "\n",
    "## 참조\n",
    "참고한 코드 출처: https://github.com/CodingVillainKor/SimpleDeepLearning/blob/main/DDPM_notebook.ipynb \n",
    "\n",
    "위 레포지토리의 원본 구현을 참고하여 수정하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1eef6e-dbfd-4cd4-98d5-3c6a2168079a",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a74eb4-1a30-4d8c-80e2-b1972bd32be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "# check cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    torch.device(\"cpu\")\n",
    "print(\" Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba63e6-ad32-4be5-b64c-fcbc44c31c2a",
   "metadata": {},
   "source": [
    "### 기본 계수 코드\n",
    "<details>\n",
    "  <summary> torch 예제 코드 (cumprod, pad 함수) </summary>\n",
    "    \n",
    "1. cumprod 함수 예제\n",
    "    \n",
    "    ``` python\n",
    "    \n",
    "    a = torch.tensor([5, 7, 10])\n",
    "    torch.cumprod(a, dim = 0)\n",
    "    # 출력: tensor([  5,  35, 350])\n",
    "    \n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "2. pad 함수 예제\n",
    "\n",
    "    ```python\n",
    "    a = torch.tensor([1,2,3,4])\n",
    "    \n",
    "    # 앞쪽에 2개, 뒤쪽에 3개 패딩 추가 , 기본 값 0 -> 9\n",
    "    F.pad(a, (2, 3), value = 9)\n",
    "    # 출력:: tensor([9, 9, 1, 2, 3, 4, 9, 9, 9])\n",
    "    ```\n",
    "</details>\n",
    "\n",
    "- 기본 계수들은 $T$ 크기만큼 계산이 완료가 되어있는 tensor의 상태로 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25abe153-f1e1-4474-ba64-7487f269ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time t\n",
    "T = 1000 \n",
    "\n",
    "# beta: linear하게 증가\n",
    "betas = torch.linspace(1e-4, 0.02, T).to(device) \n",
    "\n",
    "# alpha는 beta의 변형이므로\n",
    "alphas = 1 - betas\n",
    "\n",
    "# alpha bar는 alhpa의 누적 합 -> torch의 cumprod 함수\n",
    "alphas_bar = torch.cumprod(alphas, dim = 0, ).to(device)\n",
    "\n",
    "# alpha bar 의 t-1도 sampling 과정에서 필요하다. \n",
    "# 맨 처음에 alpha가 하나도 없었다는 뜻으로 맨 앞에 1을 추가.\n",
    "alphas_bar_prev = F.pad(alphas_bar[:-1], (1, 0), value = 1)\n",
    "\n",
    "#training에 필요한 변수\n",
    "sqrt_alphas_bar = torch.sqrt(alphas_bar).to(device)\n",
    "sqrt_one_minus_alphas_bar = torch.sqrt(1. - alphas_bar).to(device)\n",
    "\n",
    "# sampling에 필요한 변수\n",
    "reciprocal_alphas_sqrt = torch.sqrt(1. / alphas_bar).to(device)\n",
    "reciprocal_alphasm1_sqrt = torch.sqrt(1. / alphas_bar - 1.).to(device)\n",
    "posterior_mean_coef1 = torch.sqrt(alphas_bar_prev) * betas / (1. - alphas_bar).to(device)\n",
    "posterior_mean_coef2 = torch.sqrt(alphas) * (1. - alphas_bar_prev) / (1. - alphas_bar).to(device)\n",
    "sigmas = (betas * (1. - alphas_bar_prev) / (1. - alphas_bar)).to(device) # 시그마는 betas를 사용해도 무관함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba39202-e5da-4337-a0c2-f608b3a9781f",
   "metadata": {},
   "source": [
    "### 훈련 코드\n",
    "\n",
    "1. **repeat**:\n",
    "   - \\($ \\mathbf{x}_0 \\sim q(\\mathbf{x}_0) $\\)  (데이터 분포에서 샘플링)\n",
    "   - \\($ t \\sim \\text{Uniform}(\\{1, \\dots, T\\})$ \\)  (랜덤한 시간 스텝 샘플링)\n",
    "   - \\($ \\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ \\)  (정규분포에서 노이즈 샘플링)\n",
    "   - Gradient descent step on:\n",
    "\n",
    "   - $\n",
    "     \\nabla_\\theta \\left\\| \\epsilon - \\epsilon_\\theta \\left( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t \\right) \\right\\|^2\n",
    "     $\n",
    "\n",
    "2. **until converged**\n",
    "\n",
    "<details>\n",
    "  <summary> torch 예제 코드 (gather, view 함수) </summary>\n",
    "\n",
    "1. gather 함수\n",
    "    \n",
    "    ```python\n",
    "        # 원본 텐서\n",
    "        coeff = torch.tensor([10, 20, 30, 40, 50])\n",
    "        \n",
    "        # 특정 인덱스를 가져올 t 텐서\n",
    "        t = torch.tensor([0, 2, 4])  # 인덱스 0, 2, 4를 가져오도록 지정\n",
    "        \n",
    "        # gather 사용 (dim=0)\n",
    "        coeff_t = torch.gather(coeff, index=t, dim=0)\n",
    "        # 출력: tensor([10, 30, 50])\n",
    "    ```\n",
    "    \n",
    "2. view 함수\n",
    "\n",
    "    ```python\n",
    "    # 예제 텐서\n",
    "    coeff_t = torch.tensor([1, 2, 3, 4])  # Shape: (4,)\n",
    "    \n",
    "    # 변환할 차원 리스트\n",
    "    dims = [2, 2]  # 여기서 len(dims) = 2\n",
    "    \n",
    "    # 새로운 차원으로 변환\n",
    "    B = coeff_t.shape[0] # 4\n",
    "    reshaped_tensor = coeff_t.view([B] + [1] * len(dims))\n",
    "    # 출력: torch.Size([4, 1, 1])\n",
    "    ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7c11c7-999c-45fe-ab5b-6d2655d322ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_and_expand(coeff, t, xshape):\n",
    "    ''' \n",
    "    t시간에 해당하는 계수(인덱스)를 계수 텐서(coeff)에서 가져오고, \n",
    "    해당 계수들을 batch size에 맞게 확장하는 함수 \n",
    "    '''\n",
    "    # 입력 텐서의 차원 분리\n",
    "    batch_size, *dims = xshape # batch_size는 첫 번째 차원, dims는 나머지 차원\n",
    "\n",
    "     # t시간에 해당하는 계수 가져오기\n",
    "    coeff_t = torch.gather(coeff, index = t, dim = 0) # Shape: (len(t), ) = (batch_size, )\n",
    "    \n",
    "    # 차원 확장\n",
    "    coeff_t = coeff_t.view([batch_size] + [1] * len(dims)) # 나머지 차원들에 맞게 확장 -> 이후의 계산 차원을 맞추기 위하여\n",
    "    return coeff_t\n",
    "    \n",
    "def train(model, x_0): # x_0: 데이터 분포에서 샘플링한 입력 데이터\n",
    "    # 랜덤한 시간 스텝에서 배치 사이즈(x_0.shape[0])만큼 샘플링\n",
    "    t = torch.randint(T, size = (x_0.shape[0], ), device = x_0.device)\\\n",
    "    \n",
    "    # 정규분포에서 노이즈 샘플링, shape이 batch와 같게\n",
    "    eps = torch.randn_like(x_0)\n",
    "    \n",
    "    # model input, batch 들간 계수\n",
    "    # 모든 batch가 같은 t를 사용하지 않기 때문에 해당 함수를 사용해야함\n",
    "    x_t = gather_and_expand(sqrt_alphas_bar, t, x_0.shape)*x_0 + gather_and_expand(sqrt_one_minus_alphas_bar, t, x_0.shape) * eps\n",
    "    \n",
    "    # eps와 model output mse 구하기\n",
    "    loss = F.mse_loss(model(x_t, t), eps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46c59a-e665-478b-b8e1-ddf0801cc9d4",
   "metadata": {},
   "source": [
    "### 샘플링 코드\n",
    "1. **Initialize**:  \n",
    "       - \\($ \\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) $\\)  (시작 샘플은 표준 정규분포에서 샘플링)\n",
    "    \n",
    "2. **For \\( t = T, ..., 1 \\) do**:\n",
    "   - \\($ \\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ \\) if \\($ t > 1 $\\), else \\($ \\mathbf{z} = 0 $\\)  \n",
    "     (마지막 단계가 아니면 가우시안 노이즈 추가)\n",
    "\n",
    "   - 업데이트:\n",
    "     $\n",
    "     \\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \n",
    "     \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(\\mathbf{x}_t, t) \\right) \n",
    "     + \\sigma_t \\mathbf{z}\n",
    "     $\n",
    "       - 구현 시엔 $\\mu_\\theta(x_t,t) = \\tilde{\\mu}_t \\left( \\mathbf{x}_t, \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \\left( \\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta} (\\mathbf{x}_t) \\right) \\right)$ 의 수식을 사용하여 구현한다.\n",
    "       - 따라서 다음과 같아서 $ \\tilde{\\mu}_t (\\mathbf{x}_t, \\mathbf{x}_0) := \n",
    "\\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0 \n",
    "+ \\frac{\\sqrt{\\alpha_t} (1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t$ , $x_0$은 다음과 같아진다 $x_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}} \n",
    "\\left( \\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta} (\\mathbf{x}_t) \\right)$\n",
    "\n",
    "3. **Return** \\( $\\mathbf{x}_0 $\\)  (최종 생성된 샘플)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e56118c-d904-4648-a82c-31665d48613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기존\n",
    "def sample(model, x_T): # x_T: noisy data\n",
    "    x_t = x_T\n",
    "    for time_step in reversed(range(T)): # T , ..., 1 반복 수행\n",
    "        # 각 time_step를 batch size로 확장\n",
    "        t = torch.full((x_T.shape[0], ), time_step, dtype=torch.long, device=device)\n",
    "        \n",
    "        # 마지막 단계가 아니면 가우시안 노이즈 샘플링\n",
    "        z = torch.randn_like(x_t) if time_step else 0\n",
    "\n",
    "        # 업데이트 과정\n",
    "        eps = model(x_t, t) # 모델 예측\n",
    "\n",
    "        # x_0을 구함\n",
    "        print(f\"기존 차원: {gather_and_expand(reciprocal_alphas_sqrt, t, eps.shape).shape} \\n  \\\n",
    "                view 차원: {reciprocal_alphas_sqrt[t].view(eps.shape).shape}\")\n",
    "              \n",
    "        x0_predicted = gather_and_expand(reciprocal_alphas_sqrt, t, eps.shape) * x_t - \\\n",
    "            gather_and_expand(reciprocal_alphasm1_sqrt, t, eps.shape) * eps\n",
    "        \n",
    "        # 위 x_0과 함께 평균을 구한다\n",
    "        mean = gather_and_expand(posterior_mean_coef1, t, eps.shape) * x0_predicted + \\\n",
    "            gather_and_expand(posterior_mean_coef2, t, eps.shape) * x_t\n",
    "        \n",
    "        # 분산 구함\n",
    "        var = torch.sqrt(gather_and_expand(sigmas, t, eps.shape)) * z\n",
    "\n",
    "        x_t = mean + var\n",
    "        \n",
    "    # 마지막 결과 return \n",
    "    x_0 = x_t\n",
    "    return x_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac441c0-08fd-496e-9421-d17aa78c8caa",
   "metadata": {
    "id": "bO-ZCNef7TvQ"
   },
   "source": [
    "# **Prepare Dataset/Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f9097d-71be-4c2a-8a23-bbb4f535e191",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "11af90112c6e4d5f9d17265ea1be76e8",
      "ca43c3ef84a14d8b958c9f9e352ed68c",
      "fceb31b8d8954035a5cd2611fa1db129",
      "4917f4a7bcb4479885fc07d26d48714a",
      "0360c81f520e458d8387bb6f73ef4d34",
      "1337223e98864f4e95e3a3e31d26b11e",
      "936ef8ef40634ce7b90a92c5da8ba076",
      "bd854a978db84b00b8bedf40cd2536a2",
      "cc4eed40fc194805a5c09ca4f736382b",
      "53cb0d32f0d24aceb5e470a584e07807",
      "95a87db3914a4b4eb823242c03a5ebb8"
     ]
    },
    "id": "P6uQCHvLoPBM",
    "outputId": "20e261a7-4c44-41a4-f119-6dc8aaa668ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(\n",
    "    root=\"./data\", train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=32, shuffle=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3aabf-e027-45cd-9b2a-85ccbf730f56",
   "metadata": {
    "id": "LlXogTCfsoEx"
   },
   "source": [
    "# **Model architecture**\n",
    "\n",
    "https://github.com/w86763777/pytorch-ddpm/blob/master/model.py\n",
    "\n",
    "위 github에서 copy함(\\_\\_name\\_\\_ == \"\\_\\_name\\_\\_\" 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9458bddc-02a2-47fc-96f6-16650f1c20b1",
   "metadata": {
    "id": "0OBLj-cbqnsm"
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, T, d_model, dim):\n",
    "        assert d_model % 2 == 0\n",
    "        super().__init__()\n",
    "        emb = torch.arange(0, d_model, step=2) / d_model * math.log(10000)\n",
    "        emb = torch.exp(-emb)\n",
    "        pos = torch.arange(T).float()\n",
    "        emb = pos[:, None] * emb[None, :]\n",
    "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        emb = emb.view(T, d_model)\n",
    "\n",
    "        self.timembedding = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(emb),\n",
    "            nn.Linear(d_model, dim),\n",
    "            Swish(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = self.timembedding(t)\n",
    "        return emb\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        _, _, H, W = x.shape\n",
    "        x = F.interpolate(\n",
    "            x, scale_factor=2, mode='nearest')\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
    "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
    "            init.xavier_uniform_(module.weight)\n",
    "            init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "\n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.temb_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_ch),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        if attn:\n",
    "            self.attn = AttnBlock(out_ch)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = self.block1(x)\n",
    "        h += self.temb_proj(temb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = h + self.shortcut(x)\n",
    "        h = self.attn(h)\n",
    "        return h\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, T, ch, ch_mult, attn, num_res_blocks, dropout):\n",
    "        super().__init__()\n",
    "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
    "        tdim = ch * 4\n",
    "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
    "\n",
    "        self.head = nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.downblocks = nn.ModuleList()\n",
    "        chs = [ch]  # record output channel when dowmsample for upsample\n",
    "        now_ch = ch\n",
    "        for i, mult in enumerate(ch_mult):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks):\n",
    "                self.downblocks.append(ResBlock(\n",
    "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "                chs.append(now_ch)\n",
    "            if i != len(ch_mult) - 1:\n",
    "                self.downblocks.append(DownSample(now_ch))\n",
    "                chs.append(now_ch)\n",
    "\n",
    "        self.middleblocks = nn.ModuleList([\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
    "        ])\n",
    "\n",
    "        self.upblocks = nn.ModuleList()\n",
    "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                self.upblocks.append(ResBlock(\n",
    "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "            if i != 0:\n",
    "                self.upblocks.append(UpSample(now_ch))\n",
    "        assert len(chs) == 0\n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, now_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(now_ch, 3, 3, stride=1, padding=1)\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.head.weight)\n",
    "        init.zeros_(self.head.bias)\n",
    "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
    "        init.zeros_(self.tail[-1].bias)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Timestep embedding\n",
    "        temb = self.time_embedding(t)\n",
    "        # Downsampling\n",
    "        h = self.head(x)\n",
    "        hs = [h]\n",
    "        for layer in self.downblocks:\n",
    "            h = layer(h, temb)\n",
    "            hs.append(h)\n",
    "        # Middle\n",
    "        for layer in self.middleblocks:\n",
    "            h = layer(h, temb)\n",
    "        # Upsampling\n",
    "        for layer in self.upblocks:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                h = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = layer(h, temb)\n",
    "        h = self.tail(h)\n",
    "\n",
    "        assert len(hs) == 0\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d552057-9a89-49cc-a003-05cab7d0edd0",
   "metadata": {
    "id": "Xu99fy1220Ej"
   },
   "source": [
    "## **Make model,optimizer, scheduler instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3da4698-cbb8-4c94-99cd-380f111025a9",
   "metadata": {
    "id": "FWuQImErt6Rp"
   },
   "outputs": [],
   "source": [
    "model = UNet(T=T, ch=128, ch_mult=[1, 2, 2, 1], attn=[1],\n",
    "             num_res_blocks=2, dropout=0.1).to(device)\n",
    "#ema_model = copy.deepcopy(model)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "#sched = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=warmup_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8e392-854d-4420-9ef3-b680274bc671",
   "metadata": {
    "id": "mbgrZo237Gm-"
   },
   "source": [
    "# **Train Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada15dc-5727-4fcf-8ab3-af081110fd55",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nnX_9l45uNIE",
    "outputId": "ad7b5a50-1491-4065-b43f-f682b7c95d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1 , Iter: 397/1563]  Loss: 0.021"
     ]
    }
   ],
   "source": [
    "for e in range(1, 100+1):\n",
    "    model.train()\n",
    "    for i, (x, _) in enumerate(dataloader, 1):\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        loss = train(model, x)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(\"\\r[Epoch: {} , Iter: {}/{}]  Loss: {:.3f}\".format(e, i, len(dataloader), loss.item()), end='')\n",
    "    print(\"\\n> Eval at epoch {}\".format(e))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_T = torch.randn(5, 3, 32, 32).to(device)\n",
    "        x_0 = sample(model, x_T)\n",
    "        x_0 = x_0.permute(0, 2, 3, 1).clamp(0, 1).detach().cpu().numpy() * 255\n",
    "        for i in range(5):\n",
    "            cv2_imshow(x_0[i])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453d997-da59-44fb-9a04-2dbfe013516d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
